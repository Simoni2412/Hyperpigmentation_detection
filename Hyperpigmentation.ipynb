{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPgjTVsr4115E68hfFzc2Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Simoni2412/Hyperpigmentation_detection/blob/main/Hyperpigmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install ultralytics roboflow -q"
      ],
      "metadata": {
        "id": "xhmyCpA2M7wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSwIG0NPJJOg"
      },
      "outputs": [],
      "source": [
        "# YOLOv8 Segmentation for Hyperpigmentation Detection\n",
        "# Complete Google Colab Notebook\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: Setup and Installation\n",
        "# ============================================================================\n",
        "\n",
        "# Import libraries\n",
        "from ultralytics import YOLO\n",
        "from roboflow import Roboflow\n",
        "import os\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: Mount Google Drive and Load Your Dataset\n",
        "# ============================================================================\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# TODO: Update this path to where YOU uploaded your dataset in Google Drive\n",
        "# Example: '/content/drive/MyDrive/YourFolderName/hyperpigmentation_data'\n",
        "DRIVE_DATASET_PATH = '/content/drive/MyDrive/hyperpigmentation_dataset'\n",
        "\n",
        "# Local path in Colab for faster training\n",
        "COLAB_DATASET_PATH = '/content/dataset'\n",
        "\n",
        "# Check if dataset exists in Drive\n",
        "if not os.path.exists(DRIVE_DATASET_PATH):\n",
        "    print(f\"‚ùå ERROR: Dataset not found at: {DRIVE_DATASET_PATH}\")\n",
        "    print(\"\\nPlease update DRIVE_DATASET_PATH (line 30) to match your actual folder location.\")\n",
        "    print(\"\\nTo find your path:\")\n",
        "    print(\"1. Go to Files tab (left sidebar)\")\n",
        "    print(\"2. Navigate to drive ‚Üí MyDrive ‚Üí your_folder\")\n",
        "    print(\"3. Right-click on folder ‚Üí Copy path\")\n",
        "    raise FileNotFoundError(f\"Dataset not found at {DRIVE_DATASET_PATH}\")\n",
        "\n",
        "print(\"‚úì Dataset found in Google Drive!\")\n",
        "print(f\"Copying from Drive to Colab workspace for faster training...\")\n",
        "\n",
        "# Copy from Drive to Colab local storage (much faster for training)\n",
        "import shutil\n",
        "if os.path.exists(COLAB_DATASET_PATH):\n",
        "    shutil.rmtree(COLAB_DATASET_PATH)\n",
        "shutil.copytree(DRIVE_DATASET_PATH, COLAB_DATASET_PATH)\n",
        "\n",
        "dataset_location = COLAB_DATASET_PATH\n",
        "print(f\"‚úì Dataset ready at: {dataset_location}\")\n",
        "print(f\"Copy completed! Training will now be much faster.\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 3: Verify Data Structure\n",
        "# ============================================================================\n",
        "\n",
        "# Check data.yaml file\n",
        "data_yaml_path = f\"{dataset_location}/data.yaml\"\n",
        "print(\"\\n=== Data Configuration ===\")\n",
        "with open(data_yaml_path, 'r') as f:\n",
        "    print(f.read())\n",
        "\n",
        "# Check number of images\n",
        "train_images = os.listdir(f\"{dataset_location}/train/images\")\n",
        "val_images = os.listdir(f\"{dataset_location}/valid/images\")\n",
        "test_images = os.listdir(f\"{dataset_location}/test/images\") if os.path.exists(f\"{dataset_location}/test/images\") else []\n",
        "\n",
        "print(f\"\\n=== Dataset Statistics ===\")\n",
        "print(f\"Training images: {len(train_images)}\")\n",
        "print(f\"Validation images: {len(val_images)}\")\n",
        "print(f\"Test images: {len(test_images)}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 4: Visualize Sample Data\n",
        "# ============================================================================\n",
        "\n",
        "def visualize_yolo_annotation(image_path, label_path):\n",
        "    \"\"\"Visualize image with YOLO segmentation annotations\"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    h, w = img.shape[:2]\n",
        "\n",
        "    # Read YOLO annotation\n",
        "    with open(label_path, 'r') as f:\n",
        "        annotations = f.readlines()\n",
        "\n",
        "    # Draw each annotation\n",
        "    for ann in annotations:\n",
        "        data = ann.strip().split()\n",
        "        class_id = int(data[0])\n",
        "\n",
        "        # Convert normalized coordinates to pixel coordinates\n",
        "        points = []\n",
        "        for i in range(1, len(data), 2):\n",
        "            x = float(data[i]) * w\n",
        "            y = float(data[i+1]) * h\n",
        "            points.append([int(x), int(y)])\n",
        "\n",
        "        points = np.array(points, dtype=np.int32)\n",
        "\n",
        "        # Draw polygon\n",
        "        cv2.polylines(img, [points], True, (255, 0, 0), 2)\n",
        "        cv2.fillPoly(img, [points], (255, 0, 0, 50))\n",
        "\n",
        "    return img\n",
        "\n",
        "# Visualize first 3 training samples\n",
        "print(\"\\n=== Sample Training Images ===\")\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "for idx in range(min(3, len(train_images))):\n",
        "    img_name = train_images[idx]\n",
        "    img_path = f\"{dataset_location}/train/images/{img_name}\"\n",
        "    label_path = f\"{dataset_location}/train/labels/{img_name.replace('.jpg', '.txt').replace('.png', '.txt')}\"\n",
        "\n",
        "    if os.path.exists(label_path):\n",
        "        img = visualize_yolo_annotation(img_path, label_path)\n",
        "        axes[idx].imshow(img)\n",
        "        axes[idx].axis('off')\n",
        "        axes[idx].set_title(f\"Sample {idx+1}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 5: Train YOLOv8 Segmentation Model\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n=== Starting Training ===\")\n",
        "\n",
        "# Initialize model with pretrained weights\n",
        "# Options: yolov8n-seg.pt (nano), yolov8s-seg.pt (small), yolov8m-seg.pt (medium)\n",
        "# yolov8l-seg.pt (large), yolov8x-seg.pt (extra large)\n",
        "model = YOLO('yolov8m-seg.pt')  # Medium model - good balance\n",
        "\n",
        "# Training configuration\n",
        "results = model.train(\n",
        "    data=data_yaml_path,\n",
        "    epochs=100,                    # Number of epochs\n",
        "    imgsz=640,                     # Image size\n",
        "    batch=16,                      # Batch size (reduce if GPU memory issues)\n",
        "    patience=20,                   # Early stopping patience\n",
        "    save=True,                     # Save checkpoints\n",
        "    device=0,                      # 0 for GPU, 'cpu' for CPU\n",
        "    project='hyperpigmentation',   # Project name\n",
        "    name='yolov8m_seg',           # Experiment name\n",
        "    exist_ok=True,                # Overwrite existing\n",
        "\n",
        "    # Augmentation\n",
        "    hsv_h=0.015,                  # HSV-Hue augmentation\n",
        "    hsv_s=0.7,                    # HSV-Saturation augmentation\n",
        "    hsv_v=0.4,                    # HSV-Value augmentation\n",
        "    degrees=10,                   # Rotation\n",
        "    translate=0.1,                # Translation\n",
        "    scale=0.5,                    # Scale\n",
        "    flipud=0.0,                   # Vertical flip (0 for medical images)\n",
        "    fliplr=0.5,                   # Horizontal flip\n",
        "    mosaic=1.0,                   # Mosaic augmentation\n",
        "\n",
        "    # Optimization\n",
        "    optimizer='AdamW',            # Optimizer\n",
        "    lr0=0.01,                     # Initial learning rate\n",
        "    lrf=0.01,                     # Final learning rate factor\n",
        "    momentum=0.937,               # Momentum\n",
        "    weight_decay=0.0005,          # Weight decay\n",
        "    warmup_epochs=3,              # Warmup epochs\n",
        "\n",
        "    # Loss weights\n",
        "    box=7.5,                      # Box loss weight\n",
        "    cls=0.5,                      # Classification loss weight\n",
        "    dfl=1.5,                      # Distribution focal loss weight\n",
        ")\n",
        "\n",
        "print(\"\\n=== Training Complete! ===\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 6: Evaluate Model\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n=== Evaluating Model ===\")\n",
        "\n",
        "# Load best model\n",
        "best_model = YOLO('hyperpigmentation/yolov8m_seg/weights/best.pt')\n",
        "\n",
        "# Validate on validation set\n",
        "metrics = best_model.val()\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\n=== Validation Metrics ===\")\n",
        "print(f\"mAP50 (Box): {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP50-95 (Box): {metrics.box.map:.4f}\")\n",
        "print(f\"mAP50 (Mask): {metrics.seg.map50:.4f}\")\n",
        "print(f\"mAP50-95 (Mask): {metrics.seg.map:.4f}\")\n",
        "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
        "print(f\"Recall: {metrics.box.mr:.4f}\")\n",
        "\n",
        "# Display training curves\n",
        "display(Image('hyperpigmentation/yolov8m_seg/results.png'))\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 7: Test Inference\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n=== Running Inference on Test Images ===\")\n",
        "\n",
        "# Run inference on test/validation images\n",
        "test_dir = f\"{dataset_location}/test/images\" if os.path.exists(f\"{dataset_location}/test/images\") else f\"{dataset_location}/valid/images\"\n",
        "test_images_list = os.listdir(test_dir)[:5]  # First 5 images\n",
        "\n",
        "results_inference = best_model.predict(\n",
        "    source=test_dir,\n",
        "    save=True,\n",
        "    conf=0.25,                    # Confidence threshold\n",
        "    iou=0.7,                      # NMS IoU threshold\n",
        "    project='hyperpigmentation',\n",
        "    name='predictions',\n",
        "    exist_ok=True\n",
        ")\n",
        "\n",
        "print(f\"Predictions saved to: hyperpigmentation/predictions/\")\n",
        "\n",
        "# Display predictions\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, img_name in enumerate(test_images_list[:6]):\n",
        "    img_path = f\"{test_dir}/{img_name}\"\n",
        "\n",
        "    # Run prediction\n",
        "    result = best_model(img_path)[0]\n",
        "\n",
        "    # Plot result\n",
        "    img_with_pred = result.plot()\n",
        "    img_with_pred = cv2.cvtColor(img_with_pred, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    axes[idx].imshow(img_with_pred)\n",
        "    axes[idx].axis('off')\n",
        "    axes[idx].set_title(f\"Prediction {idx+1}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 8: Inference on Single Image\n",
        "# ============================================================================\n",
        "\n",
        "def predict_hyperpigmentation(image_path, conf_threshold=0.25):\n",
        "    \"\"\"\n",
        "    Predict hyperpigmentation on a single image\n",
        "\n",
        "    Args:\n",
        "        image_path: Path to image\n",
        "        conf_threshold: Confidence threshold for detection\n",
        "\n",
        "    Returns:\n",
        "        results: YOLO results object\n",
        "    \"\"\"\n",
        "    results = best_model(image_path, conf=conf_threshold)\n",
        "\n",
        "    # Get detection info\n",
        "    if len(results[0].boxes) > 0:\n",
        "        print(f\"Detected {len(results[0].boxes)} hyperpigmentation region(s)\")\n",
        "        for i, box in enumerate(results[0].boxes):\n",
        "            conf = box.conf[0].item()\n",
        "            print(f\"  Region {i+1}: Confidence = {conf:.2f}\")\n",
        "    else:\n",
        "        print(\"No hyperpigmentation detected\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Example usage\n",
        "if len(test_images_list) > 0:\n",
        "    sample_image = f\"{test_dir}/{test_images_list[0]}\"\n",
        "    print(f\"\\n=== Testing on: {test_images_list[0]} ===\")\n",
        "    result = predict_hyperpigmentation(sample_image, conf_threshold=0.25)\n",
        "\n",
        "    # Display\n",
        "    img_result = result[0].plot()\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Hyperpigmentation Detection Result\")\n",
        "    plt.show()\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 9: Export Model\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n=== Exporting Model ===\")\n",
        "\n",
        "# Export to different formats\n",
        "# ONNX for production deployment\n",
        "best_model.export(format='onnx', dynamic=True)\n",
        "print(\"Model exported to ONNX format\")\n",
        "\n",
        "# TorchScript for PyTorch deployment\n",
        "best_model.export(format='torchscript')\n",
        "print(\"Model exported to TorchScript format\")\n",
        "\n",
        "# TensorFlow Lite for mobile\n",
        "# best_model.export(format='tflite')\n",
        "# print(\"Model exported to TFLite format\")\n",
        "\n",
        "print(\"\\n=== All Done! ===\")\n",
        "print(f\"Best model weights: hyperpigmentation/yolov8m_seg/weights/best.pt\")\n",
        "print(f\"Training results: hyperpigmentation/yolov8m_seg/\")\n",
        "print(f\"Predictions: hyperpigmentation/predictions/\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 10: Save Results to Google Drive\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n=== Saving Results to Google Drive ===\")\n",
        "\n",
        "# Create results directory in Drive\n",
        "DRIVE_RESULTS_PATH = '/content/drive/MyDrive/hyperpigmentation_results'\n",
        "os.makedirs(DRIVE_RESULTS_PATH, exist_ok=True)\n",
        "\n",
        "# Save best model weights\n",
        "import shutil\n",
        "shutil.copy(\n",
        "    'hyperpigmentation/yolov8m_seg/weights/best.pt',\n",
        "    f'{DRIVE_RESULTS_PATH}/best.pt'\n",
        ")\n",
        "print(f\"‚úì Model saved to: {DRIVE_RESULTS_PATH}/best.pt\")\n",
        "\n",
        "# Save last model weights (for resuming training)\n",
        "shutil.copy(\n",
        "    'hyperpigmentation/yolov8m_seg/weights/last.pt',\n",
        "    f'{DRIVE_RESULTS_PATH}/last.pt'\n",
        ")\n",
        "print(f\"‚úì Checkpoint saved to: {DRIVE_RESULTS_PATH}/last.pt\")\n",
        "\n",
        "# Save training results/plots\n",
        "if os.path.exists('hyperpigmentation/yolov8m_seg/results.png'):\n",
        "    shutil.copy(\n",
        "        'hyperpigmentation/yolov8m_seg/results.png',\n",
        "        f'{DRIVE_RESULTS_PATH}/training_results.png'\n",
        "    )\n",
        "    print(f\"‚úì Training plots saved to: {DRIVE_RESULTS_PATH}/training_results.png\")\n",
        "\n",
        "# Save confusion matrix\n",
        "if os.path.exists('hyperpigmentation/yolov8m_seg/confusion_matrix.png'):\n",
        "    shutil.copy(\n",
        "        'hyperpigmentation/yolov8m_seg/confusion_matrix.png',\n",
        "        f'{DRIVE_RESULTS_PATH}/confusion_matrix.png'\n",
        "    )\n",
        "    print(f\"‚úì Confusion matrix saved to Drive\")\n",
        "\n",
        "print(\"\\n=== All Done! ===\")\n",
        "print(f\"üìÅ Dataset in Drive: {DRIVE_DATASET_PATH}\")\n",
        "print(f\"üìÅ Results in Drive: {DRIVE_RESULTS_PATH}\")\n",
        "print(f\"üéØ Best model: {DRIVE_RESULTS_PATH}/best.pt\")\n",
        "print(f\"\\nüí° Next time you run this notebook, it will:\")\n",
        "print(f\"   - Skip downloading (load from Drive)\")\n",
        "print(f\"   - Train faster (data already in Drive)\")\n",
        "print(f\"   - Resume training from last.pt if needed\")"
      ]
    }
  ]
}