{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPNkvW6/m165uX7XKNW0Nrp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Simoni2412/Hyperpigmentation_detection/blob/main/Hyperpigmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install ultralytics roboflow -q"
      ],
      "metadata": {
        "id": "xhmyCpA2M7wv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3895d4d-7015-4c4a-c9dc-64d24989b1b7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.9/1.2 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/94.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv8 Segmentation for Hyperpigmentation Detection\n",
        "# Complete Google Colab Notebook\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: Setup and Installation\n",
        "# ============================================================================\n",
        "\n",
        "# Import libraries\n",
        "from ultralytics import YOLO\n",
        "from roboflow import Roboflow\n",
        "import os\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyPuCmQmD-QO",
        "outputId": "d35251a3-3452-4e52-eb5d-1ddf35618aa2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 2: Mount Google Drive and Load Your Dataset\n",
        "# ============================================================================\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# TODO: Update this path to where YOU uploaded your dataset in Google Drive\n",
        "# Example: '/content/drive/MyDrive/YourFolderName/hyperpigmentation_data'\n",
        "DRIVE_DATASET_PATH = '/content/drive/MyDrive/hyperpigmentation_dataset.v2i.yolov8'\n",
        "\n",
        "# Local path in Colab for faster training\n",
        "COLAB_DATASET_PATH = '/content/dataset'\n",
        "\n",
        "# Check if dataset exists in Drive\n",
        "if not os.path.exists(DRIVE_DATASET_PATH):\n",
        "    print(f\"âŒ ERROR: Dataset not found at: {DRIVE_DATASET_PATH}\")\n",
        "    print(\"\\nPlease update DRIVE_DATASET_PATH (line 30) to match your actual folder location.\")\n",
        "    print(\"\\nTo find your path:\")\n",
        "    print(\"1. Go to Files tab (left sidebar)\")\n",
        "    print(\"2. Navigate to drive â†’ MyDrive â†’ your_folder\")\n",
        "    print(\"3. Right-click on folder â†’ Copy path\")\n",
        "    raise FileNotFoundError(f\"Dataset not found at {DRIVE_DATASET_PATH}\")\n",
        "\n",
        "print(\"âœ“ Dataset found in Google Drive!\")\n",
        "print(f\"Copying from Drive to Colab workspace for faster training...\")\n",
        "\n",
        "# Copy from Drive to Colab local storage (much faster for training)\n",
        "import shutil\n",
        "if os.path.exists(COLAB_DATASET_PATH):\n",
        "    shutil.rmtree(COLAB_DATASET_PATH)\n",
        "shutil.copytree(DRIVE_DATASET_PATH, COLAB_DATASET_PATH)\n",
        "\n",
        "dataset_location = COLAB_DATASET_PATH\n",
        "print(f\"âœ“ Dataset ready at: {dataset_location}\")\n",
        "print(f\"Copy completed! Training will now be much faster.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "ucPDr_AeEGTx",
        "outputId": "a948620d-7bd2-4a6b-a4c0-f8ef7a02ecf5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âŒ ERROR: Dataset not found at: /content/drive/MyDrive/hyperpigmentation_dataset.v2i.yolov8\n",
            "\n",
            "Please update DRIVE_DATASET_PATH (line 30) to match your actual folder location.\n",
            "\n",
            "To find your path:\n",
            "1. Go to Files tab (left sidebar)\n",
            "2. Navigate to drive â†’ MyDrive â†’ your_folder\n",
            "3. Right-click on folder â†’ Copy path\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Dataset not found at /content/drive/MyDrive/hyperpigmentation_dataset.v2i.yolov8",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-471/120433677.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2. Navigate to drive â†’ MyDrive â†’ your_folder\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"3. Right-click on folder â†’ Copy path\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dataset not found at {DRIVE_DATASET_PATH}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"âœ“ Dataset found in Google Drive!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Dataset not found at /content/drive/MyDrive/hyperpigmentation_dataset.v2i.yolov8"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 3: Verify Data Structure\n",
        "# ============================================================================\n",
        "\n",
        "# Check data.yaml file\n",
        "data_yaml_path = f\"{dataset_location}/data.yaml\"\n",
        "print(\"\\n=== Data Configuration ===\")\n",
        "with open(data_yaml_path, 'r') as f:\n",
        "    print(f.read())\n",
        "\n",
        "# Check number of images\n",
        "train_images = os.listdir(f\"{dataset_location}/train/images\")\n",
        "val_images = os.listdir(f\"{dataset_location}/valid/images\")\n",
        "test_images = os.listdir(f\"{dataset_location}/test/images\") if os.path.exists(f\"{dataset_location}/test/images\") else []\n",
        "\n",
        "print(f\"\\n=== Dataset Statistics ===\")\n",
        "print(f\"Training images: {len(train_images)}\")\n",
        "print(f\"Validation images: {len(val_images)}\")\n",
        "print(f\"Test images: {len(test_images)}\")"
      ],
      "metadata": {
        "id": "_DCbo_D1ES-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSwIG0NPJJOg"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 4: Visualize Sample Data\n",
        "# ============================================================================\n",
        "\n",
        "def visualize_yolo_annotation(image_path, label_path):\n",
        "    \"\"\"Visualize image with YOLO segmentation annotations\"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    h, w = img.shape[:2]\n",
        "\n",
        "    # Read YOLO annotation\n",
        "    with open(label_path, 'r') as f:\n",
        "        annotations = f.readlines()\n",
        "\n",
        "    # Draw each annotation\n",
        "    for ann in annotations:\n",
        "        data = ann.strip().split()\n",
        "        class_id = int(data[0])\n",
        "\n",
        "        # Convert normalized coordinates to pixel coordinates\n",
        "        points = []\n",
        "        for i in range(1, len(data), 2):\n",
        "            x = float(data[i]) * w\n",
        "            y = float(data[i+1]) * h\n",
        "            points.append([int(x), int(y)])\n",
        "\n",
        "        points = np.array(points, dtype=np.int32)\n",
        "\n",
        "        # Draw polygon\n",
        "        cv2.polylines(img, [points], True, (255, 0, 0), 2)\n",
        "        cv2.fillPoly(img, [points], (255, 0, 0, 50))\n",
        "\n",
        "    return img\n",
        "\n",
        "# Visualize first 3 training samples\n",
        "print(\"\\n=== Sample Training Images ===\")\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "for idx in range(min(3, len(train_images))):\n",
        "    img_name = train_images[idx]\n",
        "    img_path = f\"{dataset_location}/train/images/{img_name}\"\n",
        "    label_path = f\"{dataset_location}/train/labels/{img_name.replace('.jpg', '.txt').replace('.png', '.txt')}\"\n",
        "\n",
        "    if os.path.exists(label_path):\n",
        "        img = visualize_yolo_annotation(img_path, label_path)\n",
        "        axes[idx].imshow(img)\n",
        "        axes[idx].axis('off')\n",
        "        axes[idx].set_title(f\"Sample {idx+1}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 5: Train YOLOv8 Segmentation Model\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n=== Starting Training ===\")\n",
        "\n",
        "# Initialize model with pretrained weights\n",
        "# Options: yolov8n-seg.pt (nano), yolov8s-seg.pt (small), yolov8m-seg.pt (medium)\n",
        "# yolov8l-seg.pt (large), yolov8x-seg.pt (extra large)\n",
        "model = YOLO('yolov8m-seg.pt')  # Medium model - good balance\n",
        "\n",
        "# Training configuration\n",
        "results = model.train(\n",
        "    data=data_yaml_path,\n",
        "    epochs=100,                    # Number of epochs\n",
        "    imgsz=640,                     # Image size\n",
        "    batch=16,                      # Batch size (reduce if GPU memory issues)\n",
        "    patience=20,                   # Early stopping patience\n",
        "    save=True,                     # Save checkpoints\n",
        "    device=0,                      # 0 for GPU, 'cpu' for CPU\n",
        "    project='hyperpigmentation',   # Project name\n",
        "    name='yolov8m_seg',           # Experiment name\n",
        "    exist_ok=True,                # Overwrite existing\n",
        "\n",
        "    # Augmentation\n",
        "    hsv_h=0.015,                  # HSV-Hue augmentation\n",
        "    hsv_s=0.7,                    # HSV-Saturation augmentation\n",
        "    hsv_v=0.4,                    # HSV-Value augmentation\n",
        "    degrees=10,                   # Rotation\n",
        "    translate=0.1,                # Translation\n",
        "    scale=0.5,                    # Scale\n",
        "    flipud=0.0,                   # Vertical flip (0 for medical images)\n",
        "    fliplr=0.5,                   # Horizontal flip\n",
        "    mosaic=1.0,                   # Mosaic augmentation\n",
        "\n",
        "    # Optimization\n",
        "    optimizer='AdamW',            # Optimizer\n",
        "    lr0=0.01,                     # Initial learning rate\n",
        "    lrf=0.01,                     # Final learning rate factor\n",
        "    momentum=0.937,               # Momentum\n",
        "    weight_decay=0.0005,          # Weight decay\n",
        "    warmup_epochs=3,              # Warmup epochs\n",
        "\n",
        "    # Loss weights\n",
        "    box=7.5,                      # Box loss weight\n",
        "    cls=0.5,                      # Classification loss weight\n",
        "    dfl=1.5,                      # Distribution focal loss weight\n",
        ")\n",
        "\n",
        "print(\"\\n=== Training Complete! ===\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 6: Evaluate Model\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n=== Evaluating Model ===\")\n",
        "\n",
        "# Load best model\n",
        "best_model = YOLO('hyperpigmentation/yolov8m_seg/weights/best.pt')\n",
        "\n",
        "# Validate on validation set\n",
        "metrics = best_model.val()\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\n=== Validation Metrics ===\")\n",
        "print(f\"mAP50 (Box): {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP50-95 (Box): {metrics.box.map:.4f}\")\n",
        "print(f\"mAP50 (Mask): {metrics.seg.map50:.4f}\")\n",
        "print(f\"mAP50-95 (Mask): {metrics.seg.map:.4f}\")\n",
        "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
        "print(f\"Recall: {metrics.box.mr:.4f}\")\n",
        "\n",
        "# Display training curves\n",
        "display(Image('hyperpigmentation/yolov8m_seg/results.png'))\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 7: Test Inference\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n=== Running Inference on Test Images ===\")\n",
        "\n",
        "# Run inference on test/validation images\n",
        "test_dir = f\"{dataset_location}/test/images\" if os.path.exists(f\"{dataset_location}/test/images\") else f\"{dataset_location}/valid/images\"\n",
        "test_images_list = os.listdir(test_dir)[:5]  # First 5 images\n",
        "\n",
        "results_inference = best_model.predict(\n",
        "    source=test_dir,\n",
        "    save=True,\n",
        "    conf=0.25,                    # Confidence threshold\n",
        "    iou=0.7,                      # NMS IoU threshold\n",
        "    project='hyperpigmentation',\n",
        "    name='predictions',\n",
        "    exist_ok=True\n",
        ")\n",
        "\n",
        "print(f\"Predictions saved to: hyperpigmentation/predictions/\")\n",
        "\n",
        "# Display predictions\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, img_name in enumerate(test_images_list[:6]):\n",
        "    img_path = f\"{test_dir}/{img_name}\"\n",
        "\n",
        "    # Run prediction\n",
        "    result = best_model(img_path)[0]\n",
        "\n",
        "    # Plot result\n",
        "    img_with_pred = result.plot()\n",
        "    img_with_pred = cv2.cvtColor(img_with_pred, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    axes[idx].imshow(img_with_pred)\n",
        "    axes[idx].axis('off')\n",
        "    axes[idx].set_title(f\"Prediction {idx+1}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 8: Inference on Single Image\n",
        "# ============================================================================\n",
        "\n",
        "def predict_hyperpigmentation(image_path, conf_threshold=0.25):\n",
        "    \"\"\"\n",
        "    Predict hyperpigmentation on a single image\n",
        "\n",
        "    Args:\n",
        "        image_path: Path to image\n",
        "        conf_threshold: Confidence threshold for detection\n",
        "\n",
        "    Returns:\n",
        "        results: YOLO results object\n",
        "    \"\"\"\n",
        "    results = best_model(image_path, conf=conf_threshold)\n",
        "\n",
        "    # Get detection info\n",
        "    if len(results[0].boxes) > 0:\n",
        "        print(f\"Detected {len(results[0].boxes)} hyperpigmentation region(s)\")\n",
        "        for i, box in enumerate(results[0].boxes):\n",
        "            conf = box.conf[0].item()\n",
        "            print(f\"  Region {i+1}: Confidence = {conf:.2f}\")\n",
        "    else:\n",
        "        print(\"No hyperpigmentation detected\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Example usage\n",
        "if len(test_images_list) > 0:\n",
        "    sample_image = f\"{test_dir}/{test_images_list[0]}\"\n",
        "    print(f\"\\n=== Testing on: {test_images_list[0]} ===\")\n",
        "    result = predict_hyperpigmentation(sample_image, conf_threshold=0.25)\n",
        "\n",
        "    # Display\n",
        "    img_result = result[0].plot()\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Hyperpigmentation Detection Result\")\n",
        "    plt.show()\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 9: Export Model\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n=== Exporting Model ===\")\n",
        "\n",
        "# Export to different formats\n",
        "# ONNX for production deployment\n",
        "best_model.export(format='onnx', dynamic=True)\n",
        "print(\"Model exported to ONNX format\")\n",
        "\n",
        "# TorchScript for PyTorch deployment\n",
        "best_model.export(format='torchscript')\n",
        "print(\"Model exported to TorchScript format\")\n",
        "\n",
        "# TensorFlow Lite for mobile\n",
        "# best_model.export(format='tflite')\n",
        "# print(\"Model exported to TFLite format\")\n",
        "\n",
        "print(\"\\n=== All Done! ===\")\n",
        "print(f\"Best model weights: hyperpigmentation/yolov8m_seg/weights/best.pt\")\n",
        "print(f\"Training results: hyperpigmentation/yolov8m_seg/\")\n",
        "print(f\"Predictions: hyperpigmentation/predictions/\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 10: Save Results to Google Drive\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n=== Saving Results to Google Drive ===\")\n",
        "\n",
        "# Create results directory in Drive\n",
        "DRIVE_RESULTS_PATH = '/content/drive/MyDrive/hyperpigmentation_results'\n",
        "os.makedirs(DRIVE_RESULTS_PATH, exist_ok=True)\n",
        "\n",
        "# Save best model weights\n",
        "import shutil\n",
        "shutil.copy(\n",
        "    'hyperpigmentation/yolov8m_seg/weights/best.pt',\n",
        "    f'{DRIVE_RESULTS_PATH}/best.pt'\n",
        ")\n",
        "print(f\"âœ“ Model saved to: {DRIVE_RESULTS_PATH}/best.pt\")\n",
        "\n",
        "# Save last model weights (for resuming training)\n",
        "shutil.copy(\n",
        "    'hyperpigmentation/yolov8m_seg/weights/last.pt',\n",
        "    f'{DRIVE_RESULTS_PATH}/last.pt'\n",
        ")\n",
        "print(f\"âœ“ Checkpoint saved to: {DRIVE_RESULTS_PATH}/last.pt\")\n",
        "\n",
        "# Save training results/plots\n",
        "if os.path.exists('hyperpigmentation/yolov8m_seg/results.png'):\n",
        "    shutil.copy(\n",
        "        'hyperpigmentation/yolov8m_seg/results.png',\n",
        "        f'{DRIVE_RESULTS_PATH}/training_results.png'\n",
        "    )\n",
        "    print(f\"âœ“ Training plots saved to: {DRIVE_RESULTS_PATH}/training_results.png\")\n",
        "\n",
        "# Save confusion matrix\n",
        "if os.path.exists('hyperpigmentation/yolov8m_seg/confusion_matrix.png'):\n",
        "    shutil.copy(\n",
        "        'hyperpigmentation/yolov8m_seg/confusion_matrix.png',\n",
        "        f'{DRIVE_RESULTS_PATH}/confusion_matrix.png'\n",
        "    )\n",
        "    print(f\"âœ“ Confusion matrix saved to Drive\")\n",
        "\n",
        "print(\"\\n=== All Done! ===\")\n",
        "print(f\"ğŸ“ Dataset in Drive: {DRIVE_DATASET_PATH}\")\n",
        "print(f\"ğŸ“ Results in Drive: {DRIVE_RESULTS_PATH}\")\n",
        "print(f\"ğŸ¯ Best model: {DRIVE_RESULTS_PATH}/best.pt\")\n",
        "print(f\"\\nğŸ’¡ Next time you run this notebook, it will:\")\n",
        "print(f\"   - Skip downloading (load from Drive)\")\n",
        "print(f\"   - Train faster (data already in Drive)\")\n",
        "print(f\"   - Resume training from last.pt if needed\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple YOLOv8 Training for Hyperpigmentation Detection\n",
        "# Just 3 steps: Setup â†’ Train â†’ Test\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: Setup\n",
        "# ============================================================================\n",
        "!pip install ultralytics -q\n",
        "\n",
        "from ultralytics import YOLO\n",
        "from google.colab import drive\n",
        "import torch\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "# print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: Train\n",
        "# ============================================================================\n",
        "\n",
        "# TODO: Update this path to your dataset folder in Google Drive\n",
        "DATA_PATH = '/content/drive/MyDrive/Hyperpigmentation /hyperpigmentation_dataset.v2i.yolov8/data.yaml'\n",
        "\n",
        "# Load model and train\n",
        "model = YOLO('yolov8m-seg.pt')\n",
        "\n",
        "results = model.train(\n",
        "    data=DATA_PATH,\n",
        "    epochs=100,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    patience=20,\n",
        "    project='results',\n",
        "    name='run',\n",
        "    device=0\n",
        ")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 3: Test & Save\n",
        "# ============================================================================\n",
        "\n",
        "# Validate\n",
        "best_model = YOLO('results/run/weights/best.pt')\n",
        "metrics = best_model.val()\n",
        "\n",
        "print(f\"\\nmAP50: {metrics.seg.map50:.3f}\")\n",
        "print(f\"mAP50-95: {metrics.seg.map:.3f}\")\n",
        "\n",
        "# Test on an image\n",
        "TEST_IMAGE = '/content/drive/MyDrive/Hyperpigmentation /Original photo/IMG_0193.JPG'  # Update this\n",
        "results = best_model(TEST_IMAGE)\n",
        "results[0].show()\n",
        "\n",
        "# Save to Drive\n",
        "!cp results/run/weights/best.pt /content/drive/MyDrive/hyperpigmentation_model.pt\n",
        "print(\"\\nâœ“ Model saved to Google Drive!\")"
      ],
      "metadata": {
        "id": "uoIYwdpMGbCS",
        "outputId": "8d348857-bc8a-4078-9f9e-b9bd8ad04bea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Ultralytics 8.4.19 ğŸš€ Python-3.12.12 torch-2.10.0+cu128 CUDA:0 (Tesla T4, 14913MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/Hyperpigmentation /hyperpigmentation_dataset.v2i.yolov8/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m-seg.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=run2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=results, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/segment/results/run2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 108.3MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, 16, None, [192, 384, 576]]\n",
            "YOLOv8m-seg summary: 192 layers, 27,240,227 parameters, 27,240,211 gradients, 104.7 GFLOPs\n",
            "\n",
            "Transferred 531/537 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.3MB 312.0MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.8Â±0.5 ms, read: 0.0Â±0.0 MB/s, size: 30.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Hyperpigmentation /hyperpigmentation_dataset.v2i.yolov8/train/labels... 58 images, 0 backgrounds, 0 corrupt: 12% â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 58/501 1.3it/s 50.6s<5:49"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N6sjVUNLGumr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}