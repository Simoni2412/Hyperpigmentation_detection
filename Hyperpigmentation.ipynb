{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPNkvW6/m165uX7XKNW0Nrp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Simoni2412/Hyperpigmentation_detection/blob/main/Hyperpigmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install ultralytics roboflow -q"
      ],
      "metadata": {
        "id": "xhmyCpA2M7wv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3895d4d-7015-4c4a-c9dc-64d24989b1b7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.9/1.2 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/94.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv8 Segmentation for Hyperpigmentation Detection\n",
        "# Complete Google Colab Notebook\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: Setup and Installation\n",
        "# ============================================================================\n",
        "\n",
        "# Import libraries\n",
        "from ultralytics import YOLO\n",
        "from roboflow import Roboflow\n",
        "import os\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyPuCmQmD-QO",
        "outputId": "d35251a3-3452-4e52-eb5d-1ddf35618aa2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 2: Mount Google Drive and Load Your Dataset\n",
        "# ============================================================================\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# TODO: Update this path to where YOU uploaded your dataset in Google Drive\n",
        "# Example: '/content/drive/MyDrive/YourFolderName/hyperpigmentation_data'\n",
        "DRIVE_DATASET_PATH = '/content/drive/MyDrive/hyperpigmentation_dataset.v2i.yolov8'\n",
        "\n",
        "# Local path in Colab for faster training\n",
        "COLAB_DATASET_PATH = '/content/dataset'\n",
        "\n",
        "# Check if dataset exists in Drive\n",
        "if not os.path.exists(DRIVE_DATASET_PATH):\n",
        "    print(f\"âŒ ERROR: Dataset not found at: {DRIVE_DATASET_PATH}\")\n",
        "    print(\"\\nPlease update DRIVE_DATASET_PATH (line 30) to match your actual folder location.\")\n",
        "    print(\"\\nTo find your path:\")\n",
        "    print(\"1. Go to Files tab (left sidebar)\")\n",
        "    print(\"2. Navigate to drive â†’ MyDrive â†’ your_folder\")\n",
        "    print(\"3. Right-click on folder â†’ Copy path\")\n",
        "    raise FileNotFoundError(f\"Dataset not found at {DRIVE_DATASET_PATH}\")\n",
        "\n",
        "print(\"âœ“ Dataset found in Google Drive!\")\n",
        "print(f\"Copying from Drive to Colab workspace for faster training...\")\n",
        "\n",
        "# Copy from Drive to Colab local storage (much faster for training)\n",
        "import shutil\n",
        "if os.path.exists(COLAB_DATASET_PATH):\n",
        "    shutil.rmtree(COLAB_DATASET_PATH)\n",
        "shutil.copytree(DRIVE_DATASET_PATH, COLAB_DATASET_PATH)\n",
        "\n",
        "dataset_location = COLAB_DATASET_PATH\n",
        "print(f\"âœ“ Dataset ready at: {dataset_location}\")\n",
        "print(f\"Copy completed! Training will now be much faster.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "ucPDr_AeEGTx",
        "outputId": "a948620d-7bd2-4a6b-a4c0-f8ef7a02ecf5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âŒ ERROR: Dataset not found at: /content/drive/MyDrive/hyperpigmentation_dataset.v2i.yolov8\n",
            "\n",
            "Please update DRIVE_DATASET_PATH (line 30) to match your actual folder location.\n",
            "\n",
            "To find your path:\n",
            "1. Go to Files tab (left sidebar)\n",
            "2. Navigate to drive â†’ MyDrive â†’ your_folder\n",
            "3. Right-click on folder â†’ Copy path\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Dataset not found at /content/drive/MyDrive/hyperpigmentation_dataset.v2i.yolov8",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-471/120433677.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2. Navigate to drive â†’ MyDrive â†’ your_folder\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"3. Right-click on folder â†’ Copy path\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dataset not found at {DRIVE_DATASET_PATH}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"âœ“ Dataset found in Google Drive!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Dataset not found at /content/drive/MyDrive/hyperpigmentation_dataset.v2i.yolov8"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 3: Verify Data Structure\n",
        "# ============================================================================\n",
        "\n",
        "# Check data.yaml file\n",
        "data_yaml_path = f\"{dataset_location}/data.yaml\"\n",
        "print(\"\\n=== Data Configuration ===\")\n",
        "with open(data_yaml_path, 'r') as f:\n",
        "    print(f.read())\n",
        "\n",
        "# Check number of images\n",
        "train_images = os.listdir(f\"{dataset_location}/train/images\")\n",
        "val_images = os.listdir(f\"{dataset_location}/valid/images\")\n",
        "test_images = os.listdir(f\"{dataset_location}/test/images\") if os.path.exists(f\"{dataset_location}/test/images\") else []\n",
        "\n",
        "print(f\"\\n=== Dataset Statistics ===\")\n",
        "print(f\"Training images: {len(train_images)}\")\n",
        "print(f\"Validation images: {len(val_images)}\")\n",
        "print(f\"Test images: {len(test_images)}\")"
      ],
      "metadata": {
        "id": "_DCbo_D1ES-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSwIG0NPJJOg"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 4: Visualize Sample Data\n",
        "# ============================================================================\n",
        "\n",
        "def visualize_yolo_annotation(image_path, label_path):\n",
        "    \"\"\"Visualize image with YOLO segmentation annotations\"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    h, w = img.shape[:2]\n",
        "\n",
        "    # Read YOLO annotation\n",
        "    with open(label_path, 'r') as f:\n",
        "        annotations = f.readlines()\n",
        "\n",
        "    # Draw each annotation\n",
        "    for ann in annotations:\n",
        "        data = ann.strip().split()\n",
        "        class_id = int(data[0])\n",
        "\n",
        "        # Convert normalized coordinates to pixel coordinates\n",
        "        points = []\n",
        "        for i in range(1, len(data), 2):\n",
        "            x = float(data[i]) * w\n",
        "            y = float(data[i+1]) * h\n",
        "            points.append([int(x), int(y)])\n",
        "\n",
        "        points = np.array(points, dtype=np.int32)\n",
        "\n",
        "        # Draw polygon\n",
        "        cv2.polylines(img, [points], True, (255, 0, 0), 2)\n",
        "        cv2.fillPoly(img, [points], (255, 0, 0, 50))\n",
        "\n",
        "    return img\n",
        "\n",
        "# Visualize first 3 training samples\n",
        "print(\"\\n=== Sample Training Images ===\")\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "for idx in range(min(3, len(train_images))):\n",
        "    img_name = train_images[idx]\n",
        "    img_path = f\"{dataset_location}/train/images/{img_name}\"\n",
        "    label_path = f\"{dataset_location}/train/labels/{img_name.replace('.jpg', '.txt').replace('.png', '.txt')}\"\n",
        "\n",
        "    if os.path.exists(label_path):\n",
        "        img = visualize_yolo_annotation(img_path, label_path)\n",
        "        axes[idx].imshow(img)\n",
        "        axes[idx].axis('off')\n",
        "        axes[idx].set_title(f\"Sample {idx+1}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 5: Train YOLOv8 Segmentation Model\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n=== Starting Training ===\")\n",
        "\n",
        "# Initialize model with pretrained weights\n",
        "# Options: yolov8n-seg.pt (nano), yolov8s-seg.pt (small), yolov8m-seg.pt (medium)\n",
        "# yolov8l-seg.pt (large), yolov8x-seg.pt (extra large)\n",
        "model = YOLO('yolov8m-seg.pt')  # Medium model - good balance\n",
        "\n",
        "# Training configuration\n",
        "results = model.train(\n",
        "    data=data_yaml_path,\n",
        "    epochs=100,                    # Number of epochs\n",
        "    imgsz=640,                     # Image size\n",
        "    batch=16,                      # Batch size (reduce if GPU memory issues)\n",
        "    patience=20,                   # Early stopping patience\n",
        "    save=True,                     # Save checkpoints\n",
        "    device=0,                      # 0 for GPU, 'cpu' for CPU\n",
        "    project='hyperpigmentation',   # Project name\n",
        "    name='yolov8m_seg',           # Experiment name\n",
        "    exist_ok=True,                # Overwrite existing\n",
        "\n",
        "    # Augmentation\n",
        "    hsv_h=0.015,                  # HSV-Hue augmentation\n",
        "    hsv_s=0.7,                    # HSV-Saturation augmentation\n",
        "    hsv_v=0.4,                    # HSV-Value augmentation\n",
        "    degrees=10,                   # Rotation\n",
        "    translate=0.1,                # Translation\n",
        "    scale=0.5,                    # Scale\n",
        "    flipud=0.0,                   # Vertical flip (0 for medical images)\n",
        "    fliplr=0.5,                   # Horizontal flip\n",
        "    mosaic=1.0,                   # Mosaic augmentation\n",
        "\n",
        "    # Optimization\n",
        "    optimizer='AdamW',            # Optimizer\n",
        "    lr0=0.01,                     # Initial learning rate\n",
        "    lrf=0.01,                     # Final learning rate factor\n",
        "    momentum=0.937,               # Momentum\n",
        "    weight_decay=0.0005,          # Weight decay\n",
        "    warmup_epochs=3,              # Warmup epochs\n",
        "\n",
        "    # Loss weights\n",
        "    box=7.5,                      # Box loss weight\n",
        "    cls=0.5,                      # Classification loss weight\n",
        "    dfl=1.5,                      # Distribution focal loss weight\n",
        ")\n",
        "\n",
        "print(\"\\n=== Training Complete! ===\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 6: Evaluate Model\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n=== Evaluating Model ===\")\n",
        "\n",
        "# Load best model\n",
        "best_model = YOLO('hyperpigmentation/yolov8m_seg/weights/best.pt')\n",
        "\n",
        "# Validate on validation set\n",
        "metrics = best_model.val()\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\n=== Validation Metrics ===\")\n",
        "print(f\"mAP50 (Box): {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP50-95 (Box): {metrics.box.map:.4f}\")\n",
        "print(f\"mAP50 (Mask): {metrics.seg.map50:.4f}\")\n",
        "print(f\"mAP50-95 (Mask): {metrics.seg.map:.4f}\")\n",
        "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
        "print(f\"Recall: {metrics.box.mr:.4f}\")\n",
        "\n",
        "# Display training curves\n",
        "display(Image('hyperpigmentation/yolov8m_seg/results.png'))\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 7: Test Inference\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n=== Running Inference on Test Images ===\")\n",
        "\n",
        "# Run inference on test/validation images\n",
        "test_dir = f\"{dataset_location}/test/images\" if os.path.exists(f\"{dataset_location}/test/images\") else f\"{dataset_location}/valid/images\"\n",
        "test_images_list = os.listdir(test_dir)[:5]  # First 5 images\n",
        "\n",
        "results_inference = best_model.predict(\n",
        "    source=test_dir,\n",
        "    save=True,\n",
        "    conf=0.25,                    # Confidence threshold\n",
        "    iou=0.7,                      # NMS IoU threshold\n",
        "    project='hyperpigmentation',\n",
        "    name='predictions',\n",
        "    exist_ok=True\n",
        ")\n",
        "\n",
        "print(f\"Predictions saved to: hyperpigmentation/predictions/\")\n",
        "\n",
        "# Display predictions\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, img_name in enumerate(test_images_list[:6]):\n",
        "    img_path = f\"{test_dir}/{img_name}\"\n",
        "\n",
        "    # Run prediction\n",
        "    result = best_model(img_path)[0]\n",
        "\n",
        "    # Plot result\n",
        "    img_with_pred = result.plot()\n",
        "    img_with_pred = cv2.cvtColor(img_with_pred, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    axes[idx].imshow(img_with_pred)\n",
        "    axes[idx].axis('off')\n",
        "    axes[idx].set_title(f\"Prediction {idx+1}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 8: Inference on Single Image\n",
        "# ============================================================================\n",
        "\n",
        "def predict_hyperpigmentation(image_path, conf_threshold=0.25):\n",
        "    \"\"\"\n",
        "    Predict hyperpigmentation on a single image\n",
        "\n",
        "    Args:\n",
        "        image_path: Path to image\n",
        "        conf_threshold: Confidence threshold for detection\n",
        "\n",
        "    Returns:\n",
        "        results: YOLO results object\n",
        "    \"\"\"\n",
        "    results = best_model(image_path, conf=conf_threshold)\n",
        "\n",
        "    # Get detection info\n",
        "    if len(results[0].boxes) > 0:\n",
        "        print(f\"Detected {len(results[0].boxes)} hyperpigmentation region(s)\")\n",
        "        for i, box in enumerate(results[0].boxes):\n",
        "            conf = box.conf[0].item()\n",
        "            print(f\"  Region {i+1}: Confidence = {conf:.2f}\")\n",
        "    else:\n",
        "        print(\"No hyperpigmentation detected\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Example usage\n",
        "if len(test_images_list) > 0:\n",
        "    sample_image = f\"{test_dir}/{test_images_list[0]}\"\n",
        "    print(f\"\\n=== Testing on: {test_images_list[0]} ===\")\n",
        "    result = predict_hyperpigmentation(sample_image, conf_threshold=0.25)\n",
        "\n",
        "    # Display\n",
        "    img_result = result[0].plot()\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Hyperpigmentation Detection Result\")\n",
        "    plt.show()\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 9: Export Model\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n=== Exporting Model ===\")\n",
        "\n",
        "# Export to different formats\n",
        "# ONNX for production deployment\n",
        "best_model.export(format='onnx', dynamic=True)\n",
        "print(\"Model exported to ONNX format\")\n",
        "\n",
        "# TorchScript for PyTorch deployment\n",
        "best_model.export(format='torchscript')\n",
        "print(\"Model exported to TorchScript format\")\n",
        "\n",
        "# TensorFlow Lite for mobile\n",
        "# best_model.export(format='tflite')\n",
        "# print(\"Model exported to TFLite format\")\n",
        "\n",
        "print(\"\\n=== All Done! ===\")\n",
        "print(f\"Best model weights: hyperpigmentation/yolov8m_seg/weights/best.pt\")\n",
        "print(f\"Training results: hyperpigmentation/yolov8m_seg/\")\n",
        "print(f\"Predictions: hyperpigmentation/predictions/\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 10: Save Results to Google Drive\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n=== Saving Results to Google Drive ===\")\n",
        "\n",
        "# Create results directory in Drive\n",
        "DRIVE_RESULTS_PATH = '/content/drive/MyDrive/hyperpigmentation_results'\n",
        "os.makedirs(DRIVE_RESULTS_PATH, exist_ok=True)\n",
        "\n",
        "# Save best model weights\n",
        "import shutil\n",
        "shutil.copy(\n",
        "    'hyperpigmentation/yolov8m_seg/weights/best.pt',\n",
        "    f'{DRIVE_RESULTS_PATH}/best.pt'\n",
        ")\n",
        "print(f\"âœ“ Model saved to: {DRIVE_RESULTS_PATH}/best.pt\")\n",
        "\n",
        "# Save last model weights (for resuming training)\n",
        "shutil.copy(\n",
        "    'hyperpigmentation/yolov8m_seg/weights/last.pt',\n",
        "    f'{DRIVE_RESULTS_PATH}/last.pt'\n",
        ")\n",
        "print(f\"âœ“ Checkpoint saved to: {DRIVE_RESULTS_PATH}/last.pt\")\n",
        "\n",
        "# Save training results/plots\n",
        "if os.path.exists('hyperpigmentation/yolov8m_seg/results.png'):\n",
        "    shutil.copy(\n",
        "        'hyperpigmentation/yolov8m_seg/results.png',\n",
        "        f'{DRIVE_RESULTS_PATH}/training_results.png'\n",
        "    )\n",
        "    print(f\"âœ“ Training plots saved to: {DRIVE_RESULTS_PATH}/training_results.png\")\n",
        "\n",
        "# Save confusion matrix\n",
        "if os.path.exists('hyperpigmentation/yolov8m_seg/confusion_matrix.png'):\n",
        "    shutil.copy(\n",
        "        'hyperpigmentation/yolov8m_seg/confusion_matrix.png',\n",
        "        f'{DRIVE_RESULTS_PATH}/confusion_matrix.png'\n",
        "    )\n",
        "    print(f\"âœ“ Confusion matrix saved to Drive\")\n",
        "\n",
        "print(\"\\n=== All Done! ===\")\n",
        "print(f\"ğŸ“ Dataset in Drive: {DRIVE_DATASET_PATH}\")\n",
        "print(f\"ğŸ“ Results in Drive: {DRIVE_RESULTS_PATH}\")\n",
        "print(f\"ğŸ¯ Best model: {DRIVE_RESULTS_PATH}/best.pt\")\n",
        "print(f\"\\nğŸ’¡ Next time you run this notebook, it will:\")\n",
        "print(f\"   - Skip downloading (load from Drive)\")\n",
        "print(f\"   - Train faster (data already in Drive)\")\n",
        "print(f\"   - Resume training from last.pt if needed\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple YOLOv8 Training for Hyperpigmentation Detection\n",
        "# Just 3 steps: Setup â†’ Train â†’ Test\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: Setup\n",
        "# ============================================================================\n",
        "!pip install ultralytics -q\n",
        "\n",
        "from ultralytics import YOLO\n",
        "from google.colab import drive\n",
        "import torch\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "# print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: Train\n",
        "# ============================================================================\n",
        "\n",
        "# TODO: Update this path to your dataset folder in Google Drive\n",
        "DATA_PATH = '/content/drive/MyDrive/Hyperpigmentation /hyperpigmentation_dataset.v2i.yolov8/data.yaml'\n",
        "\n",
        "# Load model and train\n",
        "model = YOLO('yolov8m-seg.pt')\n",
        "\n",
        "results = model.train(\n",
        "    data=DATA_PATH,\n",
        "    epochs=100,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    patience=20,\n",
        "    project='results',\n",
        "    name='run',\n",
        "    device=0\n",
        ")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 3: Test & Save\n",
        "# ============================================================================\n",
        "\n",
        "# Validate\n",
        "best_model = YOLO('results/run/weights/best.pt')\n",
        "metrics = best_model.val()\n",
        "\n",
        "print(f\"\\nmAP50: {metrics.seg.map50:.3f}\")\n",
        "print(f\"mAP50-95: {metrics.seg.map:.3f}\")\n",
        "\n",
        "# Test on an image\n",
        "TEST_IMAGE = '/content/drive/MyDrive/Hyperpigmentation /Original photo/IMG_0193.JPG'  # Update this\n",
        "results = best_model(TEST_IMAGE)\n",
        "results[0].show()\n",
        "\n",
        "# Save to Drive\n",
        "!cp results/run/weights/best.pt /content/drive/MyDrive/hyperpigmentation_model.pt\n",
        "print(\"\\nâœ“ Model saved to Google Drive!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uoIYwdpMGbCS",
        "outputId": "631a9855-f49c-4798-ada8-25f0aa544797"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Ultralytics 8.4.19 ğŸš€ Python-3.12.12 torch-2.10.0+cu128 CUDA:0 (Tesla T4, 14913MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/Hyperpigmentation /hyperpigmentation_dataset.v2i.yolov8/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m-seg.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=run2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=results, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/segment/results/run2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 108.3MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, 16, None, [192, 384, 576]]\n",
            "YOLOv8m-seg summary: 192 layers, 27,240,227 parameters, 27,240,211 gradients, 104.7 GFLOPs\n",
            "\n",
            "Transferred 531/537 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.3MB 312.0MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.8Â±0.5 ms, read: 0.0Â±0.0 MB/s, size: 30.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Hyperpigmentation /hyperpigmentation_dataset.v2i.yolov8/train/labels... 501 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 501/501 1.3it/s 6:37\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/Hyperpigmentation /hyperpigmentation_dataset.v2i.yolov8/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 4.2Â±3.1 ms, read: 0.0Â±0.0 MB/s, size: 32.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Hyperpigmentation /hyperpigmentation_dataset.v2i.yolov8/valid/labels... 16 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 16/16 1.3s/it 20.9s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/Hyperpigmentation /hyperpigmentation_dataset.v2i.yolov8/valid/labels.cache\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
            "Plotting labels to /content/runs/segment/results/run2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/segment/results/run2\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      1/100      7.03G      2.331       4.37      3.019      2.141          0         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.2it/s 26.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
            "                   all         16         53     0.0024      0.208    0.00163   0.000466   0.000218     0.0189   0.000127   1.27e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      2/100      7.42G      2.226      3.849      2.601      2.043          0         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 22.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
            "                   all         16         53          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      3/100      7.33G      2.227      3.793      2.577      2.005          0         51        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.2it/s 0.5s\n",
            "                   all         16         53          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      4/100      7.24G      2.238      3.708       2.43      1.996          0         52        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.3it/s 24.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
            "                   all         16         53      0.133     0.0189    0.00628    0.00124    0.00213     0.0377   0.000741   0.000112\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      5/100      7.24G      2.174       3.63      2.433      1.974          0         40        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.3it/s 24.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.7it/s 0.6s\n",
            "                   all         16         53     0.0514      0.132     0.0277     0.0166      0.048     0.0377     0.0191     0.0099\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      6/100      7.24G       2.11       3.57      2.358      1.911          0         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
            "                   all         16         53       0.15     0.0943     0.0428     0.0138     0.0745       0.17     0.0341    0.00938\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      7/100      7.24G      2.047       3.55       2.34      1.878          0         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.3it/s 23.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.2it/s 0.5s\n",
            "                   all         16         53      0.423      0.208       0.19     0.0855      0.533      0.208      0.204     0.0744\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      8/100      7.24G      2.058      3.457      2.272      1.855          0         45        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.3it/s 24.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
            "                   all         16         53      0.307      0.309      0.233     0.0836      0.456      0.189      0.189     0.0807\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      9/100      7.24G      2.003      3.444      2.227      1.832          0         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.7it/s 0.6s\n",
            "                   all         16         53       0.18      0.151      0.102     0.0254       0.18      0.151       0.09     0.0259\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     10/100      7.24G      1.956      3.296      2.105       1.79          0         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
            "                   all         16         53      0.293      0.208      0.203     0.0861      0.502      0.151       0.18     0.0783\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     11/100      7.24G      1.999      3.354      2.171      1.801          0         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.3it/s 23.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
            "                   all         16         53      0.294      0.212       0.17     0.0574      0.282      0.189      0.151     0.0345\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     12/100      7.24G      1.948      3.275      2.054      1.762          0         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.3it/s 23.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.6it/s 0.6s\n",
            "                   all         16         53      0.473      0.226       0.27       0.12      0.561      0.208      0.236      0.093\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     13/100      7.24G      1.966      3.314      2.056       1.76          0         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
            "                   all         16         53      0.538      0.358      0.339      0.126      0.523       0.34      0.311      0.121\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     14/100      7.24G       1.91       3.18      1.935      1.724          0         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
            "                   all         16         53      0.577      0.283      0.342      0.165      0.787      0.302      0.363       0.14\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     15/100      7.24G      1.864      3.178      1.951      1.729          0         43        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.3it/s 24.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
            "                   all         16         53      0.366      0.415      0.357      0.161      0.371      0.334      0.294      0.114\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     16/100      7.24G      1.878      3.169      1.949      1.729          0         42        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.5it/s 0.7s\n",
            "                   all         16         53      0.404      0.434      0.332      0.167      0.609      0.358       0.36      0.134\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     17/100      7.24G      1.885      3.117      1.914      1.698          0         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
            "                   all         16         53     0.0126      0.396    0.00988    0.00391     0.0126      0.396    0.00856    0.00295\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     18/100      7.24G      1.852      3.108      1.863      1.694          0         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.3it/s 23.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
            "                   all         16         53      0.474      0.377      0.387      0.139      0.631      0.283      0.335       0.12\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     19/100      7.24G      1.804      3.094      1.837      1.638          0         50        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.3it/s 23.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
            "                   all         16         53      0.315      0.321      0.252      0.112      0.343      0.321      0.228     0.0929\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     20/100      7.24G      1.817      3.079      1.827      1.672          0         38        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.7it/s 0.6s\n",
            "                   all         16         53      0.393      0.377       0.37      0.175      0.475      0.396      0.388       0.13\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     21/100      7.24G      1.794      3.002      1.754      1.641          0         37        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.7it/s 0.4s\n",
            "                   all         16         53      0.781      0.377      0.483      0.179       0.86      0.415      0.507      0.159\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     22/100      7.24G      1.743      2.974      1.691      1.625          0         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.3it/s 23.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
            "                   all         16         53      0.572      0.434      0.447      0.176      0.572      0.434      0.432      0.162\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     23/100      7.24G      1.707      2.901      1.605      1.563          0         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.6it/s 0.6s\n",
            "                   all         16         53      0.368      0.415      0.369      0.171      0.362      0.396      0.347       0.15\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     24/100      7.24G      1.753      2.939       1.63      1.575          0         43        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
            "                   all         16         53      0.509      0.415      0.423      0.168      0.462      0.377      0.389      0.167\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     25/100      7.24G      1.684      2.864      1.652      1.594          0         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.3it/s 23.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
            "                   all         16         53      0.711      0.321      0.419      0.192      0.711      0.321      0.401      0.167\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     26/100      7.24G      1.675      2.861      1.572      1.565          0         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.3it/s 23.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
            "                   all         16         53      0.445      0.415      0.356      0.114      0.427      0.396      0.339      0.102\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     27/100      7.24G      1.663      2.872      1.575      1.568          0         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.3it/s 24.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.2it/s 0.5s\n",
            "                   all         16         53      0.512      0.358      0.396       0.17      0.551      0.302      0.368      0.142\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     28/100      7.24G       1.66      2.806      1.531      1.533          0         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
            "                   all         16         53      0.752      0.434      0.499      0.208      0.724      0.415      0.478      0.193\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     29/100      7.24G      1.661      2.815      1.544      1.544          0         49        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
            "                   all         16         53      0.626      0.264      0.324      0.147       0.43      0.302      0.313       0.13\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     30/100      7.24G      1.662        2.8      1.533      1.531          0         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.3it/s 23.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
            "                   all         16         53       0.68      0.302      0.357       0.15      0.451       0.34      0.322       0.15\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     31/100      7.24G      1.635       2.79      1.504      1.523          0         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.3it/s 23.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.5it/s 0.7s\n",
            "                   all         16         53      0.641      0.506      0.536      0.234      0.592      0.434      0.475      0.204\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     32/100      7.24G      1.623      2.778      1.492      1.522          0         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
            "                   all         16         53      0.591      0.491      0.525      0.216      0.638      0.453      0.484      0.179\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     33/100      7.24G      1.588      2.714      1.427      1.489          0         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.3it/s 23.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
            "                   all         16         53      0.592       0.34      0.431      0.179      0.861      0.302      0.406      0.175\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     34/100      7.24G      1.585      2.727      1.381      1.492          0         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.3it/s 23.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
            "                   all         16         53      0.602      0.314      0.395      0.183      0.708      0.358      0.443      0.177\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     35/100      7.24G      1.615      2.729      1.406      1.492          0         38        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.6it/s 0.6s\n",
            "                   all         16         53      0.702      0.396      0.496      0.225      0.702      0.396      0.485      0.191\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     36/100      7.24G      1.553       2.67      1.346      1.455          0         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
            "                   all         16         53       0.68      0.547      0.567      0.238      0.657      0.528      0.527      0.198\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     37/100      7.24G      1.538      2.602      1.311      1.433          0         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.3it/s 23.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
            "                   all         16         53      0.559      0.415      0.447       0.19       0.81      0.302      0.394      0.166\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     38/100      7.24G       1.53      2.624      1.354      1.451          0         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.3it/s 23.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
            "                   all         16         53      0.494      0.491      0.453      0.184      0.646      0.453      0.455      0.173\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     39/100      7.24G      1.518      2.573      1.285      1.417          0         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.7it/s 0.6s\n",
            "                   all         16         53      0.803       0.46      0.516      0.238      0.805      0.468      0.502      0.201\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     40/100      7.24G      1.509      2.572      1.286      1.435          0         37        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.6it/s 0.6s\n",
            "                   all         16         53      0.346      0.434      0.323       0.13      0.316      0.396      0.264      0.124\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     41/100      7.24G      1.546      2.631      1.346      1.416          0         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.3it/s 23.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
            "                   all         16         53      0.562      0.436      0.487      0.199       0.54      0.421      0.372      0.165\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     42/100      7.24G      1.441       2.49      1.186      1.368          0         60        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.3it/s 23.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
            "                   all         16         53      0.728      0.509      0.538      0.239      0.698      0.491       0.51      0.219\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     43/100      7.24G      1.446      2.455       1.17      1.393          0         52        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.3it/s 23.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
            "                   all         16         53      0.546      0.472      0.448       0.22      0.488      0.396      0.389      0.174\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     44/100      7.24G      1.442      2.533      1.187      1.389          0         46        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.3it/s 24.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.7it/s 0.4s\n",
            "                   all         16         53      0.675      0.415      0.499      0.229      0.644      0.396      0.423      0.191\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     45/100      7.24G      1.464      2.512      1.173      1.395          0         37        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.5it/s 0.7s\n",
            "                   all         16         53      0.676      0.491      0.517      0.236      0.613      0.472      0.462      0.188\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     46/100      7.24G       1.44       2.51      1.211      1.386          0         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
            "                   all         16         53      0.744      0.453      0.528      0.225      0.744      0.453      0.491      0.201\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     47/100      7.24G        1.4      2.424      1.117      1.362          0         49        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
            "                   all         16         53      0.864      0.434      0.544      0.205      0.671      0.472      0.487      0.173\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     48/100      7.24G      1.376      2.361      1.076      1.315          0         40        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.3it/s 23.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
            "                   all         16         53      0.724      0.396      0.487      0.241      0.693      0.396      0.436      0.187\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     49/100      7.24G       1.35      2.411      1.065      1.313          0         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.8it/s 0.6s\n",
            "                   all         16         53      0.767      0.321      0.412      0.195      0.643      0.302      0.391       0.17\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     50/100      7.24G      1.309      2.324      1.029      1.304          0         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
            "                   all         16         53      0.662      0.407      0.432      0.186      0.585      0.415      0.355       0.16\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     51/100      7.24G      1.355      2.361      1.056      1.307          0         45        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.7it/s 0.4s\n",
            "                   all         16         53      0.619      0.472      0.457       0.22      0.604       0.46       0.45      0.205\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     52/100      7.24G      1.262       2.26     0.9934       1.28          0         26        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.8it/s 0.6s\n",
            "                   all         16         53      0.533      0.453      0.449      0.207      0.533      0.453      0.422      0.177\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     53/100      7.24G      1.298      2.302      1.011      1.286          0         37        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
            "                   all         16         53      0.566      0.377      0.395      0.175      0.596      0.396      0.395      0.163\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     54/100      7.24G      1.253      2.289      0.972       1.27          0         54        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
            "                   all         16         53      0.477      0.547      0.494      0.222      0.715      0.396      0.476      0.194\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     55/100      7.24G       1.26      2.286      0.957      1.265          0         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.3it/s 23.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
            "                   all         16         53      0.528      0.472       0.46      0.218      0.528      0.472      0.408        0.2\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     56/100      7.24G      1.313      2.333      1.032      1.283          0         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.7it/s 0.6s\n",
            "                   all         16         53      0.663      0.557      0.547      0.243      0.663      0.557      0.529      0.207\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     57/100      7.24G      1.312      2.309      1.012       1.27          0         43        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
            "                   all         16         53      0.656      0.377      0.446       0.21      0.559      0.431      0.444      0.179\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     58/100      7.24G      1.275      2.251     0.9571      1.259          0         38        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
            "                   all         16         53      0.552      0.441      0.434      0.204      0.529      0.424      0.406      0.175\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     59/100      7.24G      1.276      2.278      0.985      1.286          0         46        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.3it/s 24.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
            "                   all         16         53      0.689      0.396      0.406      0.194      0.689      0.396      0.397      0.166\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     60/100      7.24G      1.266      2.266     0.9866      1.266          0         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
            "                   all         16         53      0.686      0.412      0.449      0.217       0.71      0.417      0.457      0.191\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     61/100      7.24G      1.247      2.224     0.9659      1.259          0         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.4it/s 23.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
            "                   all         16         53      0.743      0.382      0.454      0.214      0.743      0.382      0.449       0.19\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K     62/100      7.24G      1.211       2.18     0.9076      1.226          0         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 32/32 1.3it/s 24.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.7it/s 0.4s\n",
            "                   all         16         53      0.733      0.415      0.437      0.218       0.53      0.425      0.399      0.183\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 20 epochs. Best results observed at epoch 42, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=20) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "62 epochs completed in 0.437 hours.\n",
            "Optimizer stripped from /content/runs/segment/results/run2/weights/last.pt, 54.8MB\n",
            "Optimizer stripped from /content/runs/segment/results/run2/weights/best.pt, 54.8MB\n",
            "\n",
            "Validating /content/runs/segment/results/run2/weights/best.pt...\n",
            "Ultralytics 8.4.19 ğŸš€ Python-3.12.12 torch-2.10.0+cu128 CUDA:0 (Tesla T4, 14913MiB)\n",
            "YOLOv8m-seg summary (fused): 106 layers, 27,222,963 parameters, 0 gradients, 104.3 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
            "                   all         16         53      0.728      0.504      0.536      0.238      0.701      0.487      0.509      0.216\n",
            "Speed: 0.2ms preprocess, 17.2ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/segment/results/run2\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'results/run/weights/best.pt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-177/147319126.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Validate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results/run/weights/best.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/models/yolo/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;31m# Continue with default YOLO initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"RTDETR\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# if RTDETR head\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRTDETR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;31m# Delete super().training for accessing self.model.training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self, weights, task)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_ckpt_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModel\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m     \"\"\"\n\u001b[0;32m-> 1515\u001b[0;31m     \u001b[0mckpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_safe_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# load ckpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1516\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mDEFAULT_CFG_DICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_args\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m  \u001b[0;31m# combine model and default args, preferring model args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ema\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# FP32 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mtorch_safe_load\u001b[0;34m(weight, safe_only)\u001b[0m\n\u001b[1;32m   1461\u001b[0m                     \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe_pickle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1463\u001b[0;31m                 \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# e.name is missing module name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/utils/patches.py\u001b[0m in \u001b[0;36mtorch_load\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"weights_only\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1498\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1501\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFileLike\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa: SIM115\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/run/weights/best.pt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N6sjVUNLGumr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}